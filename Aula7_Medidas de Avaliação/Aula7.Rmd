---
title: "Aula 7 - Árvores/Medidas de Avaliação"
date: "25/09/18"
output:
  prettydoc::html_pretty:
    theme: architect
    highlight: github
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Calculo das medidas de Avaliação

|          |           | Referência |     | TOTAL |
|----------|-----------|------------|-----|-------|
|          |           | R$\bar{S}$ | R$S$|       |
| Predição | P$\bar{S}$| 138        | 33  | 171   |
|          | P$S$      | 30         | 61  | 91    |
|          | TOTAL     | 168        | 94  |  262  | 

Calculos das medidas de acurácia e sensibilidade:

Acurácia = $\frac{\#(PS \cap RS) \cup \#(P\bar{S} \cap R\bar{S})}{\# \Omega} = \frac{138+61}{262}$ = 0,76

Sensibilidade = $\frac{\#(P\bar{S} \cap R\bar{S})}{\#(R\bar{S})} = \frac{138}{168} = 0,821$

Especificidade = $\frac{\#(PS \cap RS)}{\#(RS)} = \frac{61}{94} = 0,649$

Acurácia balanceada = $\frac{\hbox{sensibilidade} + \hbox{especificidade}}{2} = 0,735$


# Trabalho

Utilizando o banco de dados TITANIC:

Dividir em conjunto treino e teste
Ajustar a árvore pro conjunto treino
Calcular as medidas
Comparar com a regressão logística

```{r, warning=FALSE, message=F}
library(rpart.plot) 
library(dplyr) 
library(rpart) 
library(rattle)
library(caret)
library(Metrics)

dados=data("ptitanic")  
glimpse(ptitanic)
```

### DIVIDINDO EM TREINO E TESTE
```{r}
set.seed(2006)

n <- nrow(ptitanic)
n_train <- round(0.80 * n)
```
### VETOR DE INDICES USANDO 80 \% DOS DADOS
```{r}
train_indices <- sample(1:n, n_train) 
```
###SUBCONJUNTO DE TREINAMENTO
```{r}
titanic_train <- ptitanic[train_indices, ]
```
### EXCLUINDO SUBCONJUNTO DE TREINAMENTO
```{r}
titanic_test <- ptitanic[-train_indices, ]
```
### MODELO 
```{r}
titanic_model <- rpart(formula = survived~., 
                data = titanic_train,method = "class") 

print(titanic_model)
```

### ARVORE 1 
```{r}
rpart.plot(x = titanic_model, yesno = 2, type = 0, extra = 2) 
``` 
### ARVORE 2 
```{r}
fancyRpartPlot(titanic_model)
```
### COMPARANDO COM REGRESSÃO LOGÍSTICA
```{r}
modelolog=glm(survived~. ,  data = titanic_train, family = binomial) 
anova(modelolog, test="Chisq")
```

### RAZÃO DE CHANCE (REG LOG)
```{r}
exp(coef(modelolog))
```
## PREVISAO E ACURACIA 

### Previsão
```{r}
head(predict(titanic_model, titanic_test))

head(predict(titanic_model, titanic_test, type="class"))
```
### Acurácia
```{r}
class_prediction=predict(titanic_model, titanic_test, type="class")
confusionMatrix(data = class_prediction, reference = titanic_test$survived) 
```

### COMPARAÇÃO 
```{r}
model1 <- rpart(formula = survived ~ ., data = titanic_train, method = "class", parms = list(split = "gini")) 

model2 <- rpart(formula = survived ~ ., data = titanic_train, method = "class",                        parms = list(split = "information")) 

pred1 <- predict(object = model1,               newdata = titanic_test,              type = "class")      
```

Gerando predições no conjunto de teste usando o modelo de Informação pred2 <- predict(object = model2,               newdata = titanic_test,              type = "class")

```{r}
pred2 <- predict(object = model2,newdata = titanic_test,type = "class") 

Metrics::ce(actual = titanic_test$survived,     predicted = pred1)

Metrics::ce(actual = titanic_test$survived,     predicted = pred2)

Metrics::accuracy(actual = titanic_test$survived,     predicted = pred1)

Metrics::accuracy(actual = titanic_test$survived,     predicted = pred2)
```