---
title: "Trabalho 3 - Medidas de Avaliação"
date: "27/09/18"
author: Camila Simões, Jessyka Goltara, Leonardo Filgueira
output:
  prettydoc::html_pretty:
    theme: architect
    highlight: github
---

<style>
  .col2 {
    columns: 2 200px;         /* number of columns and width in pixels*/
    -webkit-columns: 2 200px; /* chrome, safari */
    -moz-columns: 2 200px;    /* firefox */
  }
</style>

> Tarefa:

1. Dividir em conjunto de dados treino e teste.

2. Ajustar a árvore pro conjunto treino.

3. Calcular as medidas.

4. Comparar com a regressão logística.

> Pacotes Necessários 

```{r, warning=FALSE, message=F}
library(rpart.plot) 
library(dplyr) 
library(rpart) 
library(rattle)
library(caret)
library(Metrics)
```

> Definindo os Dados

O banco de dados utilizado neste trabalho é o titanic e se encontra no pacote _rpart.plot_ e apresenta as seguintes variáveis:

1. Pclass:   Classe de Passageiros (1st, 2st, 3rd)
2. Survived: Situação de sobrevivência do passageiro (Died ou Survived)
3. Sex:      Sexo do indivíduo (Male ou Female)
4. Age:      Idade do indivíduo (Em anos)
5. Sibsp:    Número de irmãos ou cônjuge a bordo (0-8)
6. Parch:    Número de pais ou filhos a bordo (0-6)

```{r echo = F}
data("ptitanic")
```


Total de Observações: `r nrow(ptitanic)`.

```{r}
data("ptitanic")  
glimpse(ptitanic)

```


A seguir, selecionaremos $80\%$ das observações da base para treinamento do modelo. Os outros $20\%$ serão utilizados para testar o modelo construído. 

```{r}
set.seed(2006)

n <- nrow(ptitanic)
n_train <- round(0.80 * n)

train_indices <- sample(1:n, n_train) #Índices selecionados

titanic_train <- ptitanic[train_indices, ] #Subconjunto de treino

titanic_test <- ptitanic[-train_indices, ] #Subconjunto Teste (Dados excluindo o treino)
```

> Árvore de Classificação 

Agora, vamos ajustar um modelo com a função `rpart` , do pacote _rpart_ citado anteriormente.A árvore classificará a variável Survived com base em todas as outras colunas de titanic_train.


```{r}
titanic_model <- rpart(formula = survived~., 
                data = titanic_train,method = "class") 

print(titanic_model)
```

Após o ajuste do modelo, vamos visualizar a árvore construída.

```{r}
rpart.plot(x = titanic_model, yesno = 2, type = 0, extra = 2) 
``` 

> Regressão Logística

A seguir, ajustaremos um modelo de regressão logística para prever a variável Survived, com base em todas as outras colunas do titanic_train . 

```{r}
modelolog <- glm(survived~. ,  data = titanic_train, family = binomial) 
anova(modelolog, test = "Chisq")

print(modelolog)
```

Adotando um nível de significância de $5\%$ , é possível afirmar que apenas a variável _parch_ não é significativa no modelo.

A partir do modelo de regressão logística ajustado, vamos calcular a razão de chances:

```{r}
exp(coef(modelolog))
```

> Previsão

- Árvore de Classificação
    ```{r}
    head(predict(titanic_model, titanic_test))
    
    head(predict(titanic_model, titanic_test, type="class"))
    ```
    
- Regressão Logística
    ```{r}
    head(predict(modelolog, titanic_test, type = "response"))
    ```

> Medidas de Avaliação

Sabendo que a acurácia consiste na proporção de acertos, vamos analisar o acerto do modelo utilizando o pacote _caret_. Além disso, encontraremos a matriz de confusão dos dois modelos e verificaremos a especificidade e sensitividade dos ajustes.

```{r}
class_prediction <- predict(titanic_model, titanic_test, type="class")
mc_arvore <- confusionMatrix(data = class_prediction, reference = titanic_test$survived) 

mc_arvore
```

Temos que remover os valores `NA`s na predição, e, para o bom funcionamento de `confusionMatrix`, também removeremos as observações correspondentes na base de teste. Usamos a função `factor`, também por uma exigência da função que calcula a acurácia, sendo que o valor `0` representa *died* e o valor `1`, *survived*.

```{r}
class_predictionGLM <- predict(modelolog, titanic_test, type = 'response') %>% 
  round() %>% 
  factor(labels = c("died", "survived"))

val_not_na <- which(!is.na(class_predictionGLM)) 
class_predictionGLM <- class_predictionGLM[val_not_na]

referencia <- titanic_test$survived[val_not_na]

mc_glm <- confusionMatrix(data = class_predictionGLM, reference = referencia) 

mc_glm
```

> Conclusão 

Pela matriz de confusão, podemos perceber que o modelo de árvore de classificação, para esta base, tem um maior número de acertos, em relação à regressão logística.

<div class="col2">
```{r}
mc_arvore$table
mc_glm$table
```
</div>

Observando a tabela abaixo, o modelo de árvore de classificação é o melhor, isso de acordo com a acurácia e sensitividade. Por outro lado, considerando a especificidade, podemos ver que a regressão logística se saiu melhor. 

```{r}
arvore <- c(mc_arvore$overall[1], mc_arvore$byClass[1:2])
reg_log <- c(mc_glm$overall[1], mc_glm$byClass[1:2])

compara <- data.frame(arvore, reg_log) %>% 
  tibble::rownames_to_column("Medida") %>% 
  mutate(Medida = c("Acurácia", "Sensitividade", "Especificidade")) %>% 
  mutate_if(is.numeric, funs(round(., 2)))

DT::datatable(compara, rownames = F, extensions = 'Buttons', colnames = c('Árvore' = 'arvore', 'Regressão logística' = 'reg_log'), options = list(
    dom = 'Bfrtip',
    buttons = c('copy', 'csv', 'excel', 'pdf', 'print')
  ))
```

Por fim, nestas circunstâncias, escolheríamos a árvore de classificação para prever a sobreviência ou morte dos passageiros.